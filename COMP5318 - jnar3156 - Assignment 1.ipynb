{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP5318: Assignment 1\n",
    "## By Jesse S. Narvasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as st\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our training data\n",
    "\n",
    "with h5py.File('./Input/train/images_training.h5','r') as H:\n",
    "    data_train = np.copy(H['datatrain'])\n",
    "with h5py.File('./Input/train/labels_training.h5','r') as H:\n",
    "    label_train = np.copy(H['labeltrain'])\n",
    "    \n",
    "# Loading our testing data\n",
    "\n",
    "with h5py.File('./Input/test/images_testing.h5','r') as H:\n",
    "    data_test = np.copy(H['datatest'])\n",
    "with h5py.File('./Input/test/labels_testing_2000.h5','r') as H:\n",
    "    label_test = np.copy(H['labeltest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 784) (30000,)\n"
     ]
    }
   ],
   "source": [
    "# Verifying our loaded training data\n",
    "\n",
    "print(data_train.shape, label_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class mappings\n",
    "class_mappings = {\n",
    "    0: 'T-shirt/Top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_image = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train = data_train.reshape((data_train.shape[0], 28, 28))\n",
    "plt.imshow(data_train[current_image], cmap=plt.get_cmap('gray'))\n",
    "plt.title(\"class \" + str(label_train[current_image]) + \": \" + class_mappings[label_train[current_image]] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SVD on it\n",
    "target_data = data_train[current_image]\n",
    "U, s, Vt = np.linalg.svd(target_data, full_matrices=False)\n",
    "S = np.diag(s)\n",
    "\n",
    "# We then create a dynamic component_num in which we'll use to determine how many components we'll keep\n",
    "# this is determine by round to 2 decimal places, and any value that is 0 will be removed\n",
    "svd_components = np.count_nonzero(np.round(s, decimals=2) > 0)\n",
    "\n",
    "target_data_reconstructed = U[:, :svd_components]\\\n",
    "    .dot(S[:svd_components, :svd_components])\\\n",
    "    .dot(Vt[:svd_components, :])\n",
    "\n",
    "plt.imshow(target_data_reconstructed, cmap=plt.get_cmap('gray'))\n",
    "plt.title(f\"After SVD using only the top {svd_components} elements\")\n",
    "plt.show()\n",
    "\n",
    "# Verifying that our reconstructed matrix is approximately equal to our original matrix (within tolerance)\n",
    "print(f'Is the original and reconstructed matrix approximately equal? {np.allclose(target_data, target_data_reconstructed)}')\n",
    "\n",
    "# Checking the compression ratio of this\n",
    "comp_ratio = ((U.shape[0] * svd_components) + (svd_components) + (svd_components * Vt.shape[1])) / (target_data.shape[0]*target_data.shape[1])\n",
    "print(f\"Our compression ratio is: {comp_ratio}\")\n",
    "\n",
    "# SSE\n",
    "svd_SSE = np.sum((target_data - target_data_reconstructed)**2)\n",
    "print(f\"SVD SSE is: {svd_SSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying mean-centering to the original dataset\n",
    "target_data_mean = target_data.mean(axis=0)\n",
    "target_data_mean_matrix = np.full((len(target_data_mean), len(target_data_mean)), target_data_mean)\n",
    "target_data_centred = target_data - target_data_mean_matrix\n",
    "\n",
    "# Now let's try PCA\n",
    "XtX = (target_data_centred.T).dot(target_data_centred)\n",
    "l, V = np.linalg.eig(XtX)\n",
    "L = np.diag(l)\n",
    "\n",
    "pca_components = np.count_nonzero(np.round(l, decimals=2) > 0)\n",
    "\n",
    "pca_projection = target_data_centred.dot(V)\n",
    "target_data_reconstructed = pca_projection[:, :pca_components]\\\n",
    "    .dot(V.T[:pca_components, :])\\\n",
    "    + target_data_mean_matrix\n",
    "\n",
    "plt.imshow(target_data_reconstructed, cmap=plt.get_cmap('gray'))\n",
    "plt.title(f\"After PCA, using only {pca_components} components\")\n",
    "plt.show()\n",
    "\n",
    "# SSE\n",
    "pca_SSE = np.sum((target_data - target_data_reconstructed)**2)\n",
    "print(f\"PCA SSE is: {pca_SSE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(data):\n",
    "    '''\n",
    "    Apply PCA on the given dataset\n",
    "    INPUT: 2D or 3D array dataset\n",
    "    OUTPUT: 3D array of principal components for the given dataset\n",
    "    '''\n",
    "    if len(data.shape) != 3:\n",
    "        data = data.reshape((data.shape[0], 28, 28))\n",
    "    \n",
    "    pca_data = np.zeros((data.shape[0], data.shape[1], data.shape[2]))\n",
    "    \n",
    "    for image_num in range(data.shape[0]):\n",
    "        # Applying mean-centering to the original dataset\n",
    "        image_mean = data[image_num].mean(axis=0)\n",
    "        # Turning it into a matrix since above is an array\n",
    "        image_mean_matrix = np.full((len(image_mean), len(image_mean)), image_mean)\n",
    "        # Subtracting our actual dataset with the mean to get the centered matrix\n",
    "        image_centred = data[image_num] - image_mean_matrix\n",
    "\n",
    "        # Now let's try PCA\n",
    "        XtX = (image_centred.T).dot(image_centred)\n",
    "        l, V = np.linalg.eig(XtX)\n",
    "\n",
    "        # Do the projection of the image matrix against our orthogonal eigenvector matrix\n",
    "        image_projected = data[image_num].dot(V)\n",
    "    \n",
    "        pca_data[image_num] = image_projected\n",
    "        \n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(data_train, label_train, data_test, K=5):\n",
    "    '''\n",
    "    k-Nearest Neighbour classifier\n",
    "    INPUT: 3D array of data_train (training dataset), 1D array of label_train (label of training dataset)\n",
    "        3D array of data_test,\n",
    "        (optional) K number of nearest neighbours\n",
    "    OUTPUT: 1D array of predicted results with the same length as data_test.shape[0]\n",
    "    '''\n",
    "    \n",
    "    if len(data_train.shape) != 3:\n",
    "        data_train = data_train.reshape((data_train.shape[0], 28, 28))\n",
    "        \n",
    "    if len(data_test.shape) != 3:\n",
    "        data_test = data_test.reshape((data_test.shape[0], 28, 28))\n",
    "        \n",
    "    pred_test = np.zeros(data_test.shape[0])\n",
    "    \n",
    "    for image_num in range(data_test.shape[0]):\n",
    "        # Calculating the distance difference between the test subject and all our training points\n",
    "        distance_diff = (np.reshape(((data_train - data_test[image_num])**2), (data_train.shape[0], 784))).sum(axis=1)\n",
    "    \n",
    "        # Getting the k nearest neighbours\n",
    "        k_nearest_neighbours = np.argsort(distance_diff)[:K]\n",
    "    \n",
    "        classes_dict = {}\n",
    "\n",
    "        # Using weighted distance, instead of simply using count\n",
    "        for neighbour_idx in k_nearest_neighbours:\n",
    "            classification = label_train[neighbour_idx]\n",
    "            if classification in classes_dict:\n",
    "                classes_dict[classification] += 1/(distance_diff[neighbour_idx]**2)\n",
    "            else:\n",
    "                classes_dict[classification] = 1/(distance_diff[neighbour_idx]**2)\n",
    "            \n",
    "        pred_class = None\n",
    "        for key in classes_dict:\n",
    "            if pred_class == None:\n",
    "                pred_class = key\n",
    "                continue\n",
    "\n",
    "            if classes_dict[key] > classes_dict[pred_class]:\n",
    "                pred_class = key\n",
    "                \n",
    "        pred_test[image_num] = pred_class\n",
    "            \n",
    "    return pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at: 2020-10-11 22:59:27.915528\n",
      "Finished at: 2020-10-11 23:11:01.511374\n"
     ]
    }
   ],
   "source": [
    "# k-Nearest Neighbours Classifier using raw data as input\n",
    "print(f\"Started at: {datetime.now()}\")\n",
    "knn_results = knn(data_train, label_train, data_test, K=5)\n",
    "print(f\"Finished at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "for n in range(label_test.shape[0]):\n",
    "    if knn_results[n] == label_test[n]:\n",
    "        correct += 1\n",
    "        \n",
    "print(f\"Accuracy result is: {correct/label_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_naive_bayes(data_train, label_train, data_test):\n",
    "    '''\n",
    "    Gaussian Naive Bayes classifier\n",
    "    INPUT: 2D/3D array of training dataset (data_train), 2D array of label on training dataset (label_train),\n",
    "        2D/3D array of test dataset (data_test)\n",
    "    OUTPUT: 2D array of predicted classes on test dataset\n",
    "    '''\n",
    "    if len(data_train.shape) != 2:\n",
    "        data_train = data_train.reshape((data_train.shape[0],784))\n",
    "        \n",
    "    if len(data_test.shape) != 2:\n",
    "        data_test = data_test.reshape((data_test.shape[0], 784))\n",
    "\n",
    "    class_indices = {}\n",
    "    for idx, image_class in enumerate(label_train):\n",
    "        if image_class not in class_indices:\n",
    "            class_indices[image_class] = [idx]\n",
    "            continue\n",
    "        else:\n",
    "            class_indices[image_class].append(idx)\n",
    "        \n",
    "    class_mean = {}\n",
    "    class_var = {}\n",
    "\n",
    "    for class_index in class_indices:\n",
    "        mean = data_train[class_indices[class_index], :].mean(axis=0)\n",
    "        var = data_train[class_indices[class_index], :].var(axis=0)\n",
    "        class_mean[class_index] = mean\n",
    "        class_var[class_index] = var\n",
    "\n",
    "    pred_test = np.zeros(data_test.shape[0])\n",
    "\n",
    "    for image_num in range(data_test.shape[0]):\n",
    "        # In order to find the length of pred_class_scores, we need to get the max value of the keys\n",
    "        # with the assumption that each number up to the max will be a class\n",
    "        # we do this instead of length because our training data may not have an entry for a class, hence, it'll\n",
    "        # result in out of range if a data exists for one higher\n",
    "        pred_class_scores = np.zeros(max(class_indices, key=int)+1)\n",
    "        for class_index in class_indices:\n",
    "            \n",
    "            # Calculating the prior probability\n",
    "            class_prob = np.log(len(class_indices[class_index])/data_train.shape[0])\n",
    "\n",
    "            for feature_num in range(data_test.shape[1]):\n",
    "                # continue if the variance is 0, since it'll be constant\n",
    "                if class_var[class_index][feature_num] == 0:\n",
    "                    continue\n",
    "                likelihood = st.norm.logpdf(x=data_test[image_num][feature_num], loc=class_mean[class_index][feature_num], scale=np.sqrt(class_var[class_index][feature_num]))\n",
    "                class_prob += likelihood\n",
    "\n",
    "            pred_class_scores[class_index] = class_prob\n",
    "\n",
    "        pred_test[image_num] = np.nanargmax(pred_class_scores)\n",
    "        \n",
    "    return pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes using raw data as input\n",
    "print(f\"Started at: {datetime.now()}\")\n",
    "nb_results = gaussian_naive_bayes(data_train, label_train, data_test)\n",
    "print(f\"Finished at: {datetime.now()}\")\n",
    "\n",
    "# Gaussian Naive Bayes applied on principal components of dataset\n",
    "print(f\"Started at: {datetime.now()}\")\n",
    "pca_data_train = apply_pca(data_train)\n",
    "pca_data_test = apply_pca(data_test)\n",
    "nb_pca_results = gaussian_naive_bayes(pca_data_train, label_train, pca_data_test)\n",
    "print(f\"Finished at: {datetime.now()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
