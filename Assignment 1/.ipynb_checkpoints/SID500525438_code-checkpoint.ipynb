{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP5318: Assignment 1\n",
    "## By SID 500525438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our training data\n",
    "\n",
    "with h5py.File('./Input/images_training.h5','r') as H:\n",
    "    data_train = np.copy(H['datatrain'])\n",
    "with h5py.File('./Input/labels_training.h5','r') as H:\n",
    "    label_train = np.copy(H['labeltrain'])\n",
    "    \n",
    "# Loading our testing data\n",
    "\n",
    "with h5py.File('./Input/images_testing.h5','r') as H:\n",
    "    data_test = np.copy(H['datatest'])\n",
    "with h5py.File('./Input/labels_testing_2000.h5','r') as H:\n",
    "    label_test = np.copy(H['labeltest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 784) (30000,)\n",
      "(5000, 784) (2000,)\n"
     ]
    }
   ],
   "source": [
    "# Verifying our loaded training data\n",
    "print(data_train.shape, label_train.shape)\n",
    "\n",
    "# Verifying our loaded testing data\n",
    "print(data_test.shape, label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class mappings\n",
    "class_mappings = {\n",
    "    0: 'T-shirt/Top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_top1_accuracy(predicted, actual):\n",
    "    '''\n",
    "    Calculates the top-1 accuracy metric, given the predicted classes against the actual classes\n",
    "    INPUT: 1D array of predicted results,\n",
    "        1D array of actual results\n",
    "    OUTPUT: percentage in decimal format of accuracy    \n",
    "    '''\n",
    "    correct = 0\n",
    "    for n in range(actual.shape[0]):\n",
    "        if predicted[n] == actual[n]:\n",
    "            correct += 1\n",
    "        \n",
    "    return correct/actual.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_prediction(predictions):\n",
    "    '''\n",
    "    Generates the output file for the predictions\n",
    "    INPUT: 1D array of predicted results\n",
    "    OUTPUT: prediction file of .h5 format\n",
    "    '''\n",
    "    with h5py.File('./Output/predicted_labels.h5','w') as H:\n",
    "        H.create_dataset('Output',data=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_split(train_ratio, data_train, label_train):\n",
    "    '''\n",
    "    Splits the dataset for X and y into training and validation datasets based on the given ratio\n",
    "    INPUT: train split ratio, training dataset, label dataset\n",
    "    OUTPUT: training data and label numpy arrays, validation data and label numpy arrays\n",
    "    '''\n",
    "    # obtain the row number where we conduct the split\n",
    "    row_split = int(train_ratio * data_train.shape[0])\n",
    "    \n",
    "    # shuffle our matrices\n",
    "    shuffled_idx = np.arange(data_train.shape[0])\n",
    "    np.random.shuffle(shuffled_idx)\n",
    "    data_train = data_train[shuffled_idx]\n",
    "    label_train = label_train[shuffled_idx]\n",
    "        \n",
    "    # create the train/test split\n",
    "    split_data_train = data_train[:row_split, :]\n",
    "    split_label_train = label_train[:row_split]\n",
    "    split_data_validation = data_train[row_split:, :]\n",
    "    split_label_validation = label_train[row_split:]\n",
    "    \n",
    "    return split_data_train, split_label_train, split_data_validation, split_label_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(data_train, data_test, n_components=45):\n",
    "    '''\n",
    "    Apply PCA on the given dataset\n",
    "    INPUT: 2D or 3D array dataset for data_train and data_test,\n",
    "        INT n_components for the number of components to be retained, or set to STR 'dynamic' to count eigenvalues > 1\n",
    "    OUTPUT: 2D array of dataset reduced to n dimensions\n",
    "    '''\n",
    "    if len(data_train.shape) != 2:\n",
    "        data_train = data_train.reshape((data_train.shape[0], data_train.shape[1]**2))\n",
    "    if len(data_test.shape) != 2:\n",
    "        data_test = data_test.reshape((data_test.shape[0], data_test.shape[1]**2))\n",
    "    \n",
    "    # Need to get the mean of each feature, for mean normalisation/centreing\n",
    "    data_train_mean = data_train.mean(axis=0)\n",
    "    data_test_mean = data_test.mean(axis=0)\n",
    "    # Feature means should now be zero, or approx. close to zero - and hence centred\n",
    "    data_train_centred = np.subtract(data_train, data_train_mean)\n",
    "    data_test_centred = np.subtract(data_test, data_test_mean)\n",
    "    \n",
    "    # Checking the following, we can see that the max and min value of the entire matrix is 0 and 1\n",
    "    # hence scaling is not required\n",
    "    '''\n",
    "    print(data_train.min())\n",
    "    print(data_train.max())\n",
    "    print(data_test.min())\n",
    "    print(data_test.max())\n",
    "    '''\n",
    "    \n",
    "    covariance_matrix = (data_train_centred.T).dot(data_train_centred)\n",
    "    l, V = np.linalg.eig(covariance_matrix)\n",
    "    \n",
    "    sorted_lambda_index =  l.argsort()[::-1] # sorting our lambda values from largest to smallest\n",
    "    \n",
    "    if n_components == 'dynamic':\n",
    "        # The number of components to be retained for PCA, will be based on the number of eigenvalues which are > 1\n",
    "        n_components = np.count_nonzero(l > 1)\n",
    "        print(f'Number of factors retained is: {n_components}')\n",
    "        \n",
    "    V_n = V[:,sorted_lambda_index[:n_components]]\n",
    "    \n",
    "    # Do the projection of the image matrix against our orthogonal eigenvector matrix reduced to n columns\n",
    "    pca_data_train = data_train_centred.dot(V_n)\n",
    "    pca_data_test = data_test_centred.dot(V_n)\n",
    "    \n",
    "    return (pca_data_train, pca_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_svd(data_train, data_test, n_components=45):\n",
    "    '''\n",
    "    Apply Singular Value Decomposition for a given training dataset,\n",
    "    and subsequently apply our test dataset onto the same orthognal V\n",
    "    '''\n",
    "    if len(data_train.shape) != 2:\n",
    "        data_train = data_train.reshape((data_train.shape[0], data_train.shape[1]**2))\n",
    "    if len(data_test.shape) != 2:\n",
    "        data_test = data_test.reshape((data_test.shape[0], data_test.shape[1]**2))\n",
    "        \n",
    "    U, s, Vt = np.linalg.svd(data_train, full_matrices=False)\n",
    "        \n",
    "    if n_components == 'dynamic':\n",
    "        # to dynamically set what our n_components value will be\n",
    "        # based on the number of singular values required to reach an energy level, where 1D array s is squared,\n",
    "        # such that we get at least 90% of the total sum squared of s        \n",
    "        s_squared = np.square(s)\n",
    "        s_squared_sum = s_squared.sum()\n",
    "        running_squared_sum = 0\n",
    "        n_components = 0\n",
    "        for idx, sing_val_sqrd in enumerate(s_squared):\n",
    "            running_squared_sum += sing_val_sqrd\n",
    "            if (running_squared_sum/s_squared_sum) > 0.9:\n",
    "                n_components = idx + 1\n",
    "                break\n",
    "        print(f'Number of components retained is: {n_components}')\n",
    "        \n",
    "    # Since our singular values in array s are already sorted from largest to smallest, we can then remove\n",
    "    # the insignificant singular values, and also remove the affected rows & columns from U and Vt\n",
    "    # However, since we'll only use Vt, then we only apply it there\n",
    "    if isinstance(n_components, int):\n",
    "        Vt = Vt[:n_components, :]\n",
    "    \n",
    "    # We do dot product between our data matrix and Vt.T because Vt is already reduced to the orthonormal vectors\n",
    "    # which have the highest singular value scores.  Moreover, we need to transpose Vt in order to do dot product\n",
    "    # with our data matrix (data_train and/or data_test)\n",
    "    svd_data_train = data_train.dot(Vt.T)\n",
    "    svd_data_test = data_test.dot(Vt.T)\n",
    "    \n",
    "    return (svd_data_train, svd_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(data_train, label_train, data_test, K=3):\n",
    "    '''\n",
    "    k-Nearest Neighbour classifier\n",
    "    INPUT: 2D/3D array of training dataset (data_train),\n",
    "        1D array of label of training dataset (label_train),\n",
    "        2D/3D array of the dataset to be predicted (data_test),\n",
    "        (optional) K number of nearest neighbours\n",
    "    OUTPUT: 1D array of predicted results with the same length as data_test.shape[0]\n",
    "    '''\n",
    "    \n",
    "    # Reshaping our input data, to ensure it's 2D\n",
    "    if len(data_train.shape) != 2:\n",
    "        data_train = data_train.reshape((data_train.shape[0], data_train.shape[1]**2))\n",
    "    if len(data_test.shape) != 2:\n",
    "        data_test = data_test.reshape((data_test.shape[0], data_test.shape[1]**2))\n",
    "        \n",
    "    # Instantiating our empty array for predicted values\n",
    "    pred_test = np.zeros(data_test.shape[0])\n",
    "    \n",
    "    for image_num in range(data_test.shape[0]):\n",
    "        # Calculating the distance difference between the test subject and all our training points\n",
    "        sum_sqrd_distances = np.sqrt((np.square(np.subtract(data_train, data_test[image_num]))).sum(axis=1))\n",
    "        #sum_sqrd_distances = np.linalg.norm(data_train - data_test[image_num], axis=1)\n",
    "    \n",
    "        # Getting the k nearest neighbours\n",
    "        k_nearest_neighbours = (np.argsort(sum_sqrd_distances))[:K]\n",
    "    \n",
    "        classes_dict = {}\n",
    "\n",
    "        # Using weighted distance, instead of simply using count\n",
    "        for neighbour_idx in k_nearest_neighbours:\n",
    "            classification = label_train[neighbour_idx]\n",
    "            if classification in classes_dict:\n",
    "                classes_dict[classification] += 1/(sum_sqrd_distances[neighbour_idx]**2)\n",
    "            else:\n",
    "                classes_dict[classification] = 1/(sum_sqrd_distances[neighbour_idx]**2)\n",
    "            \n",
    "        pred_class = None\n",
    "        for key in classes_dict:\n",
    "            if pred_class == None:\n",
    "                pred_class = key\n",
    "                continue\n",
    "\n",
    "            if classes_dict[key] > classes_dict[pred_class]:\n",
    "                pred_class = key\n",
    "                \n",
    "        pred_test[image_num] = pred_class\n",
    "            \n",
    "    return pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the best model out of each classifier by comparing accuracy results of hold-out method\n",
    "# Then run hyperparameter optimisation on the best model\n",
    "# run the results with our newly found hyper parameter against the test data\n",
    "# Output the file and get prediction\n",
    "\n",
    "# Do this for the other 2 classifiers too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken is 655.7662410736084 seconds\n",
      "Accuracy result for kNN (raw) is: 0.8275\n",
      "\n",
      "Time taken is 48.18245530128479 seconds\n",
      "Accuracy result for kNN (PCA) is: 0.84\n",
      "\n",
      "Time taken is 55.23245167732239 seconds\n",
      "Accuracy result for kNN (SVD) is: 0.8395\n"
     ]
    }
   ],
   "source": [
    "# k-Nearest Neighbours Classifier using raw data as input\n",
    "start = time.time()\n",
    "knn_results = knn(data_train, label_train, data_test, K=5)\n",
    "end = time.time()\n",
    "print(f\"Time taken is {end-start} seconds\")\n",
    "accuracy = calc_top1_accuracy(knn_results, label_test)\n",
    "print(f\"Accuracy result for kNN (raw) is: {accuracy}\")\n",
    "print()\n",
    "\n",
    "# k-Nearest Neighbours Classifier with PCA\n",
    "start = time.time()\n",
    "pca_data_train, pca_data_test = apply_pca(data_train, data_test, n_components=43)\n",
    "knn_pca_results = knn(pca_data_train, label_train, pca_data_test, K=5)\n",
    "end = time.time()\n",
    "print(f\"Time taken is {end-start} seconds\")\n",
    "accuracy = calc_top1_accuracy(knn_pca_results, label_test)\n",
    "print(f\"Accuracy result for kNN (PCA) is: {accuracy}\")\n",
    "print()\n",
    "\n",
    "# k-Nearest Neighbours Classifier with SVD\n",
    "start = time.time()\n",
    "svd_data_train, svd_data_test = apply_svd(data_train, data_test, n_components=43)\n",
    "knn_svd_results = knn(svd_data_train, label_train, svd_data_test, K=5)\n",
    "end = time.time()\n",
    "print(f\"Time taken is {end-start} seconds\")\n",
    "accuracy = calc_top1_accuracy(knn_svd_results, label_test)\n",
    "print(f\"Accuracy result for kNN (SVD) is: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy result for K Nearest Neighbours with K=3 is 0.8467407407407407\n",
      "Average accuracy result for K Nearest Neighbours with K=6 is 0.8501851851851852\n",
      "Average accuracy result for K Nearest Neighbours with K=9 is 0.8509259259259259\n",
      "Average accuracy result for K Nearest Neighbours with K=12 is 0.8483703703703703\n",
      "Average accuracy result for K Nearest Neighbours with K=15 is 0.8507037037037036\n",
      "Average accuracy result for K Nearest Neighbours with K=18 is 0.8468518518518519\n",
      "Average accuracy result for K Nearest Neighbours with K=21 is 0.8478888888888889\n",
      "Average accuracy result for K Nearest Neighbours with K=24 is 0.8415925925925926\n",
      "Average accuracy result for K Nearest Neighbours with K=27 is 0.8414814814814816\n",
      "Average accuracy result for K Nearest Neighbours with K=30 is 0.8386296296296297\n",
      "Average accuracy result for K Nearest Neighbours with K=33 is 0.8424444444444444\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameterisation\n",
    "\n",
    "# Finding the best value of K (PCA)\n",
    "\n",
    "N_RUNS = 3\n",
    "\n",
    "for K in range(3,36, 3):\n",
    "    accuracy_results = []\n",
    "    for _ in range(N_RUNS):\n",
    "        # do the shuffle and train/validation split\n",
    "        split_data_train, split_label_train, split_data_validation, split_label_validation = train_validation_split(0.7, data_train, label_train)\n",
    "        \n",
    "        pca_data_train, pca_data_test = apply_pca(split_data_train, split_data_validation, n_components=43)\n",
    "        knn_pca_results = knn(pca_data_train, split_label_train, pca_data_test, K=K)\n",
    "        accuracy = calc_top1_accuracy(knn_pca_results, split_label_validation)\n",
    "        accuracy_results.append(accuracy)\n",
    "    print(f'Average accuracy result for K Nearest Neighbours with K={K} is {(sum(accuracy_results))/N_RUNS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy result for K Nearest Neighbours with n_components=35 is 0.8504444444444444\n",
      "Average accuracy result for K Nearest Neighbours with n_components=40 is 0.8473333333333334\n",
      "Average accuracy result for K Nearest Neighbours with n_components=45 is 0.8597777777777778\n",
      "Average accuracy result for K Nearest Neighbours with n_components=50 is 0.8534444444444444\n",
      "Average accuracy result for K Nearest Neighbours with n_components=55 is 0.8518888888888889\n",
      "Average accuracy result for K Nearest Neighbours with n_components=60 is 0.8548888888888889\n",
      "Average accuracy result for K Nearest Neighbours with n_components=65 is 0.8473333333333334\n",
      "Average accuracy result for K Nearest Neighbours with n_components=70 is 0.8511111111111112\n",
      "Average accuracy result for K Nearest Neighbours with n_components=75 is 0.8541111111111112\n",
      "Average accuracy result for K Nearest Neighbours with n_components=80 is 0.8576666666666667\n",
      "Average accuracy result for K Nearest Neighbours with n_components=85 is 0.8577777777777778\n",
      "Average accuracy result for K Nearest Neighbours with n_components=90 is 0.8537777777777777\n",
      "Average accuracy result for K Nearest Neighbours with n_components=95 is 0.8533333333333334\n",
      "Average accuracy result for K Nearest Neighbours with n_components=100 is 0.8491111111111111\n",
      "Average accuracy result for K Nearest Neighbours with n_components=105 is 0.8553333333333333\n",
      "Average accuracy result for K Nearest Neighbours with n_components=110 is 0.8587777777777778\n",
      "Average accuracy result for K Nearest Neighbours with n_components=115 is 0.8566666666666667\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameterisation\n",
    "\n",
    "# Finding the best value of K (PCA)\n",
    "\n",
    "N_RUNS = 1\n",
    "\n",
    "for n_component in range(35,120, 5):\n",
    "    accuracy_results = []\n",
    "    for _ in range(N_RUNS):\n",
    "        # do the shuffle and train/validation split\n",
    "        split_data_train, split_label_train, split_data_validation, split_label_validation = train_validation_split(0.7, data_train, label_train)\n",
    "        \n",
    "        pca_data_train, pca_data_test = apply_pca(split_data_train, split_data_validation, n_components=n_component)\n",
    "        knn_pca_results = knn(pca_data_train, split_label_train, pca_data_test, K=9)\n",
    "        accuracy = calc_top1_accuracy(knn_pca_results, split_label_validation)\n",
    "        accuracy_results.append(accuracy)\n",
    "    print(f'Average accuracy result for K Nearest Neighbours with n_components={n_component} is {(sum(accuracy_results))/N_RUNS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy result for K Nearest Neighbours with K=3 is 0.8448888888888889\n",
      "Average accuracy result for K Nearest Neighbours with K=6 is 0.8495555555555555\n",
      "Average accuracy result for K Nearest Neighbours with K=9 is 0.8505185185185186\n",
      "Average accuracy result for K Nearest Neighbours with K=12 is 0.8490000000000001\n",
      "Average accuracy result for K Nearest Neighbours with K=15 is 0.8478148148148148\n",
      "Average accuracy result for K Nearest Neighbours with K=18 is 0.8447037037037036\n",
      "Average accuracy result for K Nearest Neighbours with K=21 is 0.8432962962962963\n",
      "Average accuracy result for K Nearest Neighbours with K=24 is 0.8406296296296296\n",
      "Average accuracy result for K Nearest Neighbours with K=27 is 0.8453703703703703\n",
      "Average accuracy result for K Nearest Neighbours with K=30 is 0.8434074074074074\n",
      "Average accuracy result for K Nearest Neighbours with K=33 is 0.8407037037037037\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameterisation\n",
    "\n",
    "# Finding the best value of K (SVD)\n",
    "\n",
    "N_RUNS = 3\n",
    "\n",
    "for K in range(3,36, 3):\n",
    "    accuracy_results = []\n",
    "    for _ in range(N_RUNS):\n",
    "        # do the shuffle and train/validation split\n",
    "        split_data_train, split_label_train, split_data_validation, split_label_validation = train_validation_split(0.7, data_train, label_train)\n",
    "        \n",
    "        svd_data_train, svd_data_test = apply_svd(split_data_train, split_data_validation, n_components=43)\n",
    "        knn_svd_results = knn(svd_data_train, split_label_train, svd_data_test, K=K)\n",
    "        accuracy = calc_top1_accuracy(knn_svd_results, split_label_validation)\n",
    "        accuracy_results.append(accuracy)\n",
    "    print(f'Average accuracy result for K Nearest Neighbours with K={K} is {(sum(accuracy_results))/N_RUNS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy result for n_components retained for SVD with n_component=70 is 0.8511111111111112\n",
      "Average accuracy result for n_components retained for SVD with n_component=75 is 0.8492222222222222\n",
      "Average accuracy result for n_components retained for SVD with n_component=80 is 0.8512222222222222\n",
      "Average accuracy result for n_components retained for SVD with n_component=85 is 0.856\n",
      "Average accuracy result for n_components retained for SVD with n_component=90 is 0.8476666666666667\n",
      "Average accuracy result for n_components retained for SVD with n_component=95 is 0.8532222222222222\n",
      "Average accuracy result for n_components retained for SVD with n_component=100 is 0.8566666666666667\n",
      "Average accuracy result for n_components retained for SVD with n_component=105 is 0.8495555555555555\n",
      "Average accuracy result for n_components retained for SVD with n_component=110 is 0.8494444444444444\n",
      "Average accuracy result for n_components retained for SVD with n_component=115 is 0.8537777777777777\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameterisation\n",
    "\n",
    "# Finding the best value of n_component (SVD)\n",
    "\n",
    "N_RUNS = 1\n",
    "\n",
    "for n_component in range(70,120, 5):\n",
    "    accuracy_results = []\n",
    "    for _ in range(N_RUNS):\n",
    "        # do the shuffle and train/validation split\n",
    "        split_data_train, split_label_train, split_data_validation, split_label_validation = train_validation_split(0.7, data_train, label_train)\n",
    "        \n",
    "        svd_data_train, svd_data_test = apply_svd(split_data_train, split_data_validation, n_components=n_component)\n",
    "        knn_svd_results = knn(svd_data_train, split_label_train, svd_data_test, K=10)\n",
    "        accuracy = calc_top1_accuracy(knn_svd_results, split_label_validation)\n",
    "        accuracy_results.append(accuracy)\n",
    "    print(f'Average accuracy result for n_components retained for SVD with n_component={n_component} is {(sum(accuracy_results))/N_RUNS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy result for K Nearest Neighbours with K=5 is 0.8497407407407408\n",
      "Average accuracy result for K Nearest Neighbours with K=6 is 0.8495555555555555\n",
      "Average accuracy result for K Nearest Neighbours with K=7 is 0.8508888888888889\n",
      "Average accuracy result for K Nearest Neighbours with K=8 is 0.852925925925926\n",
      "Average accuracy result for K Nearest Neighbours with K=9 is 0.8537037037037036\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameterisation\n",
    "\n",
    "# Finding the best value of K (SVD)\n",
    "\n",
    "N_RUNS = 3\n",
    "\n",
    "for K in range(5,10, 1):\n",
    "    accuracy_results = []\n",
    "    for _ in range(N_RUNS):\n",
    "        # do the shuffle and train/validation split\n",
    "        split_data_train, split_label_train, split_data_validation, split_label_validation = train_validation_split(0.7, data_train, label_train)\n",
    "        \n",
    "        svd_data_train, svd_data_test = apply_svd(split_data_train, split_data_validation, n_components=75)\n",
    "        knn_svd_results = knn(svd_data_train, split_label_train, svd_data_test, K=K)\n",
    "        accuracy = calc_top1_accuracy(knn_svd_results, split_label_validation)\n",
    "        accuracy_results.append(accuracy)\n",
    "    print(f'Average accuracy result for K Nearest Neighbours with K={K} is {(sum(accuracy_results))/N_RUNS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_naive_bayes(data_train, label_train, data_test):\n",
    "    '''\n",
    "    Gaussian Naive Bayes classifier\n",
    "    INPUT: 2D/3D array of training dataset (data_train),\n",
    "        1D array of label on training dataset (label_train),\n",
    "        2D/3D array of test dataset (data_test)\n",
    "    OUTPUT: 1D array of predicted classes on test dataset\n",
    "    '''\n",
    "    \n",
    "    # Reshaping if it's not the expected shape (2D)\n",
    "    if len(data_train.shape) != 2:\n",
    "        data_train = data_train.reshape((data_train.shape[0], data_train.shape[1]**2))\n",
    "    if len(data_test.shape) != 2:\n",
    "        data_test = data_test.reshape((data_test.shape[0], data_test.shape[1]**2))\n",
    "\n",
    "    # Obtaining the different classes that we have present in our training data and getting index positions of each one\n",
    "    class_indices = {}\n",
    "    for idx, image_class in enumerate(label_train):\n",
    "        if image_class not in class_indices:\n",
    "            class_indices[image_class] = [idx]\n",
    "            continue\n",
    "        else:\n",
    "            class_indices[image_class].append(idx)\n",
    "        \n",
    "    class_mean = {}\n",
    "    class_var = {}\n",
    "\n",
    "    # Obtain the mean and std dev for each class of our training data\n",
    "    for class_index in class_indices:\n",
    "        class_mean[class_index] = data_train[class_indices[class_index], :].mean(axis=0)\n",
    "        class_var[class_index] = data_train[class_indices[class_index], :].var(axis=0)\n",
    "\n",
    "    pred_test = np.zeros(data_test.shape[0])\n",
    "\n",
    "    for image_num in range(data_test.shape[0]):\n",
    "        # In order to find the length of pred_class_scores, we need to get the max value of the keys\n",
    "        # with the assumption that each number up to the max will be a class\n",
    "        # we do this instead of length because our training data may not have an entry for a class, hence, it'll\n",
    "        # result in out of range if a data exists for one higher\n",
    "        pred_class_scores = np.zeros(max(class_indices, key=int)+1)\n",
    "        \n",
    "        for class_index in class_indices:\n",
    "            \n",
    "            # Calculating the logged prior probability\n",
    "            class_prob = np.log(len(class_indices[class_index])/data_train.shape[0])\n",
    "\n",
    "            # Calculating the sum of the logged conditional probability\n",
    "            likelihood_array = st.norm.logpdf(x=data_test[image_num], loc=class_mean[class_index], scale=np.sqrt(class_var[class_index]))\n",
    "            class_prob = class_prob + np.nansum(likelihood_array) # we use nansum to avoid nan likelihoods, because these are obtained from points with zero variance\n",
    "\n",
    "            # Storing the result in our results array, so we can keep track of which class has the highest\n",
    "            pred_class_scores[class_index] = class_prob\n",
    "\n",
    "        # Class with the highest prob is the predicted class for the image, which is stored in our final pred_test array\n",
    "        pred_test[image_num] = np.nanargmax(pred_class_scores)\n",
    "        \n",
    "    return pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameterisation\n",
    "\n",
    "# Finding the best n_components value for PCA\n",
    "\n",
    "N_RUNS = 3\n",
    "\n",
    "for n_component in range(70,100, 5):\n",
    "    accuracy_results = []\n",
    "    for _ in range(N_RUNS):\n",
    "        # do the shuffle and train/validation split\n",
    "        split_data_train, split_label_train, split_data_validation, split_label_validation = train_validation_split(0.7, data_train, label_train)\n",
    "        \n",
    "        pca_data_train, pca_data_test = apply_pca(split_data_train, split_data_validation, n_components=n_component)\n",
    "        nb_pca_results = gaussian_naive_bayes(pca_data_train, split_label_train, pca_data_test)\n",
    "        accuracy = calc_top1_accuracy(nb_pca_results, split_label_validation)\n",
    "        accuracy_results.append(accuracy)\n",
    "    print(f'Average accuracy result for PCA components retained={n_component} is {(sum(accuracy_results))/N_RUNS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Gaussian Naive Bayes using raw data as input\n",
    "start = time.time()\n",
    "nb_results = gaussian_naive_bayes(data_train, label_train, data_test)\n",
    "end = time.time()\n",
    "print(f\"Time taken is {end-start} seconds\")\n",
    "accuracy = calc_top1_accuracy(nb_results, label_test)\n",
    "print(f\"Accuracy result for NB (raw) is: {accuracy}\")\n",
    "print()\n",
    "'''\n",
    "\n",
    "# Gaussian Naive Bayes applied on principal components of dataset\n",
    "start = time.time()\n",
    "pca_data_train, pca_data_test = apply_pca(data_train, data_test, n_components=95)\n",
    "nb_pca_results = gaussian_naive_bayes(pca_data_train, label_train, pca_data_test)\n",
    "end = time.time()\n",
    "print(f\"Time taken is {end-start} seconds\")\n",
    "accuracy = calc_top1_accuracy(nb_pca_results, label_test)        \n",
    "print(f\"Accuracy result for NB (PCA) is: {accuracy}\")\n",
    "print()\n",
    "'''\n",
    "# Gaussian Naive Bayes applied on SVD of dataset\n",
    "start = time.time()\n",
    "svd_data_train, svd_data_test = apply_svd(data_train, data_test, n_components=50)\n",
    "nb_svd_results = gaussian_naive_bayes(svd_data_train, label_train, svd_data_test)\n",
    "end = time.time()\n",
    "print(f\"Time taken is {end-start} seconds\")\n",
    "accuracy = calc_top1_accuracy(nb_svd_results, label_test)\n",
    "print(f\"Accuracy result for NB (SVD) is: {accuracy}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_prediction(nb_svd_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your predicted label will be the label which has the maximum odds - defined by softmax\n",
    "def calc_logistic_loss(weights, X, y, LAMBDA):\n",
    "    \n",
    "    # Basically the vector of inputs for our sigmoid function\n",
    "    z = X.dot(weights)\n",
    "    \n",
    "    # Now placing it inside our sigmoid function.  This will produce vector of probabilities of size N\n",
    "    prob = 1/(1 + np.exp(-z))\n",
    "    \n",
    "    # getting the gradient at the current point\n",
    "    grad_loss = X.T.dot((prob - y))\n",
    "    \n",
    "    # getting the current loss, since we want to do minimisation problem (not maximisation)\n",
    "    curr_loss = -((np.log(prob)).T.dot(y) + (np.log(1-prob)).T.dot(1-y)) + (LAMBDA/2 * (weights.T.dot(weights)))\n",
    "    \n",
    "    return grad_loss, curr_loss[0]\n",
    "    \n",
    "\n",
    "pca_data_train, pca_data_test = apply_pca(data_train, data_test, n_components=95)\n",
    "\n",
    "X0 = pca_data_train[np.where(label_train==0)[0], :]\n",
    "X1 = pca_data_train[np.where(label_train==1)[0], :]\n",
    "y0 = np.zeros(X0.shape[0])\n",
    "y1 = np.ones(X1.shape[0])\n",
    "\n",
    "X = np.concatenate((X0, X1), axis=0)\n",
    "y = np.concatenate((y0, y1))[:, np.newaxis]\n",
    "\n",
    "N, D = X.shape\n",
    "\n",
    "LEARNING_RATE = 0.5\n",
    "LAMBDA = 100\n",
    "\n",
    "# select a random starting point for our gradient descent\n",
    "weights = np.random.random(D)[:, np.newaxis]\n",
    "\n",
    "max_iter = 100\n",
    "\n",
    "loss_array = []\n",
    "\n",
    "for epoch in range(max_iter):\n",
    "    dloss, current_loss = calc_logistic_loss(weights, X, y, LAMBDA)\n",
    "    weights = weights - (LEARNING_RATE * (dloss / N))\n",
    "    \n",
    "    loss_array.append(current_loss)\n",
    "    \n",
    "plt.plot(list(range(0,max_iter)), loss_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9787234042553191\n"
     ]
    }
   ],
   "source": [
    "X0 = pca_data_test[np.where(label_test==0)[0], :]\n",
    "X1 = pca_data_test[np.where(label_test==1)[0], :]\n",
    "y0 = np.zeros(X0.shape[0])\n",
    "y1 = np.ones(X1.shape[0])\n",
    "\n",
    "X = np.concatenate((X0, X1), axis=0)\n",
    "y = np.concatenate((y0, y1))\n",
    "\n",
    "test_z = X.dot(weights)\n",
    "test_prob = 1/(1 + np.exp(-test_z))\n",
    "test_prob[np.squeeze(test_prob>=0.5)] = 1\n",
    "test_prob[np.squeeze(test_prob<0.5)] = 0\n",
    "\n",
    "accuracy = calc_top1_accuracy(test_prob, y)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfT0lEQVR4nO3de5Bc5X3m8e/Tc9f9NhJCIyzZCBNgMViyIttZrxfZQbGzFkmJ3clugjbRlhxCZe1sKglsajfJbpE1SdZOSBaqKJMgsGNQ5NionCWxVjK5GUseGQwIkDUYLA0SukvoOprLb//ot0fdrdZM6zLqmTnPp6rrnP6d855536HQM+c9p08rIjAzM8vVugNmZjYyOBDMzAxwIJiZWeJAMDMzwIFgZmZJfa07cLFmzJgR8+bNq3U3zMxGla1btx6IiNZK20ZtIMybN4+Ojo5ad8PMbFSR9KPzbfOUkZmZAQ4EMzNLHAhmZgY4EMzMLHEgmJkZ4EAwM7PEgWBmZkAGA+G7bx7if39zO2d6+2vdFTOzESVzgbD1R4f5002d9PY7EMzMimUuEHLKL/29QGZmpTIXCCKfCP1OBDOzEtkLhMIZQm27YWY24mQwEPKJ4BMEM7NS2QuEtAwngplZiewFgi8qm5lVlL1ASEvngZlZqcwFQi5XuIbgSDAzK5a5QCicIfQ7D8zMSmQuEAoXEcKTRmZmJTIXCIUzBOeBmVmpqgJB0q9J2ibpZUlfkdQsaZqkDZJ2pOXUov3vk9Qpabuk24vqCyW9lLY9qPShAElNkp5K9c2S5l32kSa5gTMEMzMrNmQgSJoD/GdgUUTcBNQB7cC9wMaIWABsTO+RdEPafiOwDHhIUl063MPAamBBei1L9VXA4Yi4FvgC8MBlGV3F8eSXfnSFmVmpaqeM6oEWSfXAOGA3sBxYk7avAe5I68uBJyOiOyLeADqBxZJmA5Mi4rnI3+LzeFmbwrHWAUsLZw+X29kPpg3H0c3MRq8hAyEi3gL+CNgJ7AGORsQ3gVkRsSftsweYmZrMAXYVHaIr1eak9fJ6SZuI6AWOAtPL+yJptaQOSR379++vdowlPGVkZlZZNVNGU8n/BT8fuBoYL+nnB2tSoRaD1AdrU1qIeCQiFkXEotbW1sE7PkTv+n3fqZlZiWqmjD4GvBER+yOiB/hr4EPA3jQNRFruS/t3AXOL2reRn2LqSuvl9ZI2aVpqMnDoYgY0lGGZhzIzGwOqCYSdwBJJ49K8/lLgVWA9sDLtsxJ4Oq2vB9rTnUPzyV883pKmlY5JWpKOc1dZm8KxVgCbYpg+SuynnZqZVVY/1A4RsVnSOuB7QC/wPPAIMAFYK2kV+dC4M+2/TdJa4JW0/z0R0ZcOdzfwGNACPJNeAI8CT0jqJH9m0H5ZRlfBwDem+SqCmVmJIQMBICJ+B/idsnI3+bOFSvvfD9xfod4B3FShfpoUKMPt7G2nV+KnmZmNHhn8pLIfbmdmVkn2AsFfoWlmVlEGA8EXlc3MKsleIKSlp4zMzEplLxA8ZWRmVlHmAiHnKSMzs4oyFwhnvzHNiWBmVix7gVCYMnIemJmVyFwgFM4R/EllM7NSmQuEnM8QzMwqylwg+HMIZmaVZS8Q0tJTRmZmpbIXCJ4yMjOrKHOB4K/QNDOrLHOBMPAVmj5FMDMrkblAOPsso5p2w8xsxMlcIBSmjDxpZGZWKnOB4G9MMzOrLHuBgD+HYGZWSfYCYeC2UyeCmVmxIQNB0nslvVD0ekfSZyVNk7RB0o60nFrU5j5JnZK2S7q9qL5Q0ktp24NKHxuW1CTpqVTfLGnesIwWfx+Cmdn5DBkIEbE9Im6JiFuAhcBJ4GvAvcDGiFgAbEzvkXQD0A7cCCwDHpJUlw73MLAaWJBey1J9FXA4Iq4FvgA8cFlGV0Fhysi3nZqZlbrQKaOlwOsR8SNgObAm1dcAd6T15cCTEdEdEW8AncBiSbOBSRHxXOTnax4va1M41jpgaeHs4XLzTUZmZpVdaCC0A19J67MiYg9AWs5M9TnArqI2Xak2J62X10vaREQvcBSYXv7DJa2W1CGpY//+/RfY9XSMtHQemJmVqjoQJDUCnwL+aqhdK9RikPpgbUoLEY9ExKKIWNTa2jpENyrL5XyXkZlZJRdyhvBTwPciYm96vzdNA5GW+1K9C5hb1K4N2J3qbRXqJW0k1QOTgUMX0Leq+Ss0zcwqu5BA+DnOThcBrAdWpvWVwNNF9fZ059B88hePt6RppWOSlqTrA3eVtSkcawWwKYbpvlDfZWRmVll9NTtJGgd8HPh0UflzwFpJq4CdwJ0AEbFN0lrgFaAXuCci+lKbu4HHgBbgmfQCeBR4QlIn+TOD9ksY01BjIfVzuH6EmdmoVFUgRMRJyi7yRsRB8ncdVdr/fuD+CvUO4KYK9dOkQBlufridmVllGfykcuH7EJwIZmbFshcIaekzBDOzUpkLhIFvTHMgmJmVyFwgnH38tRPBzKxY5gKhwHFgZlYqc4Fw9vHXte2HmdlIk7lA8FdomplVlrlA8FdomplVlr1A8FdomplVlLlAyA08y8iJYGZWLHOB4CkjM7PKMhcI4IfbmZlVkrlAGJ4v5jQzG/0yFwh+dIWZWWWZCwR/Y5qZWWXZCwR/UtnMrKLsBULhonKN+2FmNtJkLxD8tFMzs4oyGwg+RTAzK5XBQPBXaJqZVVJVIEiaImmdpNckvSrpg5KmSdogaUdaTi3a/z5JnZK2S7q9qL5Q0ktp24NK/zpLapL0VKpvljTvso80yfmisplZRdWeIfwJ8LcRcT3wPuBV4F5gY0QsADam90i6AWgHbgSWAQ9JqkvHeRhYDSxIr2Wpvgo4HBHXAl8AHrjEcZ1X4aKyH11hZlZqyECQNAn4CPAoQESciYgjwHJgTdptDXBHWl8OPBkR3RHxBtAJLJY0G5gUEc9F/rkRj5e1KRxrHbC0cPZwuckPtzMzq6iaM4R3A/uBv5D0vKQvShoPzIqIPQBpOTPtPwfYVdS+K9XmpPXyekmbiOgFjgLTyzsiabWkDkkd+/fvr3KIZcdIS08ZmZmVqiYQ6oH3Aw9HxK3ACdL00HlU+ss+BqkP1qa0EPFIRCyKiEWtra2D9/p8nZM/h2BmVkk1gdAFdEXE5vR+HfmA2JumgUjLfUX7zy1q3wbsTvW2CvWSNpLqgcnAoQsdTDXOflLZkWBmVmzIQIiIt4Fdkt6bSkuBV4D1wMpUWwk8ndbXA+3pzqH55C8eb0nTSsckLUnXB+4qa1M41gpgUwzTv9ieMjIzq6y+yv1+FfiypEbgh8Avkg+TtZJWATuBOwEiYpukteRDoxe4JyL60nHuBh4DWoBn0gvyF6yfkNRJ/syg/RLHdV4DU0ZOBDOzElUFQkS8ACyqsGnpefa/H7i/Qr0DuKlC/TQpUIZbbuDRFVfip5mZjR7Z+6SyH25nZlZR5gIBX1Q2M6soc4GQG5aPu5mZjX6ZC4TCRWU//trMrFT2AiEtnQdmZqWyFwgDzzIyM7NimQuE3MDnEGrcETOzESZzgVDgawhmZqUyFwjD81BtM7PRL3OBkPOjK8zMKspcIBROEPzoCjOzUtkLBF9UNjOrKHuBkJb+Ck0zs1LZC4SBZxnVth9mZiNNBgPBF5XNzCrJXCBA/izBcWBmViqbgYCnjMzMymUyEHKSLyqbmZXJZCBI/hyCmVm5qgJB0puSXpL0gqSOVJsmaYOkHWk5tWj/+yR1Stou6fai+sJ0nE5JDypd4ZXUJOmpVN8sad5lHmfpeJCnjMzMylzIGcK/johbImJRen8vsDEiFgAb03sk3QC0AzcCy4CHJNWlNg8Dq4EF6bUs1VcBhyPiWuALwAMXP6Sh5S8qOxHMzIpdypTRcmBNWl8D3FFUfzIiuiPiDaATWCxpNjApIp6L/D2fj5e1KRxrHbC0cPYwHCRfVDYzK1dtIATwTUlbJa1OtVkRsQcgLWem+hxgV1HbrlSbk9bL6yVtIqIXOApMv7ChVC8/ZeREMDMrVl/lfh+OiN2SZgIbJL02yL6V/rKPQeqDtSk9cD6MVgNcc801g/d4ED5DMDM7V1VnCBGxOy33AV8DFgN70zQQabkv7d4FzC1q3gbsTvW2CvWSNpLqgcnAoQr9eCQiFkXEotbW1mq6XlH+tlMzMys2ZCBIGi9pYmEd+EngZWA9sDLtthJ4Oq2vB9rTnUPzyV883pKmlY5JWpKuD9xV1qZwrBXAphjGOR3hb0wzMytXzZTRLOBr6RpvPfCXEfG3kr4LrJW0CtgJ3AkQEdskrQVeAXqBeyKiLx3rbuAxoAV4Jr0AHgWekNRJ/syg/TKM7fw8ZWRmdo4hAyEifgi8r0L9ILD0PG3uB+6vUO8AbqpQP00KlCvB36JpZnauTH5SOZfzXUZmZuUyGQj5awi17oWZ2ciSzUDww+3MzM6RyUDI+aKymdk5MhkIIE8ZmZmVyWQg5O+gdSKYmRXLZiDgKSMzs3KZDISc/H0IZmblMhkI+W9McyKYmRXLZiDgKwhmZuWyGQieMjIzO0dGA8FfoWlmVi67geA8MDMrkc1A8FdompmdI5OBkJMvKpuZlctkIEh+dIWZWblMBkJjXY6e3v5ad8PMbETJZCA0NeQ43ds39I5mZhmSyUBorq+ju8dnCGZmxTIZCD5DMDM7V9WBIKlO0vOSvpHeT5O0QdKOtJxatO99kjolbZd0e1F9oaSX0rYHpfyDqCU1SXoq1TdLmncZx3iOpvo6TvsMwcysxIWcIXwGeLXo/b3AxohYAGxM75F0A9AO3AgsAx6SVJfaPAysBhak17JUXwUcjohrgS8AD1zUaKrU1JCj22cIZmYlqgoESW3AJ4EvFpWXA2vS+hrgjqL6kxHRHRFvAJ3AYkmzgUkR8VzkPxX2eFmbwrHWAUsLZw/DwdcQzMzOVe0Zwh8DvwkU/ys6KyL2AKTlzFSfA+wq2q8r1eak9fJ6SZuI6AWOAtPLOyFptaQOSR379++vsuvnavYZgpnZOYYMBEk/DeyLiK1VHrPSX/YxSH2wNqWFiEciYlFELGptba2yO+fyNQQzs3PVV7HPh4FPSfoE0AxMkvQlYK+k2RGxJ00H7Uv7dwFzi9q3AbtTva1CvbhNl6R6YDJw6CLHNCSfIZiZnWvIM4SIuC8i2iJiHvmLxZsi4ueB9cDKtNtK4Om0vh5oT3cOzSd/8XhLmlY6JmlJuj5wV1mbwrFWpJ8xbA+XaKqvo6cv6PPzK8zMBlRzhnA+nwPWSloF7ATuBIiIbZLWAq8AvcA9EVH4c/xu4DGgBXgmvQAeBZ6Q1En+zKD9Evo1pOaGfA529/YxrvFSfgVmZmPHBf1rGBHPAs+m9YPA0vPsdz9wf4V6B3BThfppUqBcCU31+UA43dPPuMYr9VPNzEa2TH5Subkh/7EIX0cwMzsr04HgO43MzM7KZCAUpox8hmBmdlYmA8FnCGZm58pkIJy9qOwzBDOzgkwGwoTm/M1Vx0/31rgnZmYjRyYDYWq61/TQyTM17omZ2ciRzUAYnw+EwyccCGZmBZkMhPGNdTTW5XyGYGZWJJOBIImp4xt8hmBmViSTgQD56wiHTvTUuhtmZiNGZgNh2vhGDnvKyMxsQGYDYer4Rg55ysjMbEBmA2HWxGbePnqaYfzaBTOzUSWzgTB3Wgunevp8lmBmlmQ2ENqmjgOg6/CpGvfEzGxkyHAgtAAOBDOzgswHws5DJ2vcEzOzkSGzgTCxuYGZE5vo3He81l0xMxsRMhsIANfNmsiOfcdq3Q0zsxFhyECQ1Cxpi6TvS9om6fdSfZqkDZJ2pOXUojb3SeqUtF3S7UX1hZJeStselKRUb5L0VKpvljRvGMZ6jutmTWTH3uP09/vWUzOzas4QuoHbIuJ9wC3AMklLgHuBjRGxANiY3iPpBqAduBFYBjwkqS4d62FgNbAgvZal+irgcERcC3wBeODShza062dP5FRPH28cPHElfpyZ2Yg2ZCBEXmGivSG9AlgOrEn1NcAdaX058GREdEfEG0AnsFjSbGBSRDwX+U+DPV7WpnCsdcDSwtnDcLp17hQAnt95ZLh/lJnZiFfVNQRJdZJeAPYBGyJiMzArIvYApOXMtPscYFdR865Um5PWy+slbSKiFzgKTK/Qj9WSOiR17N+/v6oBDuY9rROY2FzP93YevuRjmZmNdlUFQkT0RcQtQBv5v/ZvGmT3Sn/ZxyD1wdqU9+ORiFgUEYtaW1uH6PXQcjnxgXnT+KcdB/wICzPLvAu6yygijgDPkp/735umgUjLfWm3LmBuUbM2YHeqt1Wol7SRVA9MBg5dSN8u1m3Xz2TnoZO8vt+3n5pZtlVzl1GrpClpvQX4GPAasB5YmXZbCTyd1tcD7enOofnkLx5vSdNKxyQtSdcH7iprUzjWCmBTXKE/2W+7Pj/TtfHVfUPsaWY2ttVXsc9sYE26UygHrI2Ib0h6DlgraRWwE7gTICK2SVoLvAL0AvdERF861t3AY0AL8Ex6ATwKPCGpk/yZQfvlGFw1rp7Swo/NnsTGV/fx6X/1niv1Y83MRpwhAyEiXgRurVA/CCw9T5v7gfsr1DuAc64/RMRpUqDUwk/eMIsHN+1g16GTzJ02rlbdMDOrqUx/Urng335gLgKe/O7OWnfFzKxmHAjAnCkt3Hb9TJ76bhdnevtr3R0zs5pwICR3fXAeB45381dbdw29s5nZGORASP7lghksfNdU/mxTJ6d7+oZuYGY2xjgQEkn8+sevY8/R0/z5P79R6+6YmV1xDoQiH7p2BrffOIsHN+bvODIzyxIHQpnf/dSN1En8+trv09vnC8xmlh0OhDKzJ7fwP++4iS1vHuLzG35Q6+6YmV0xDoQKfvb9bbR/YC4PPfs639z2dq27Y2Z2RTgQzuN3P3Uj72ubzK9+5Xk2//BgrbtjZjbsHAjn0dxQx1/84mLaprbwn9Z08Ly/M8HMxjgHwiCmjW/kiVU/zrQJjfyHL27mH3dc+pfymJmNVA6EIVw9pYW/+uUPcs20cfzSY9/lie/8yF+mY2ZjkgOhCjMnNvPUpz/IT1w7g//29Zf5jXUv+tPMZjbmOBCqNLmlgUdXfoDPLF3Auq1dfPLBf+SFXUdq3S0zs8vGgXABcjnxax+/jsd/aTEnz/Txsw/9Mw/87WucPNNb666ZmV0yB8JF+Mh1rfzdr32EFQvbePjZ17ntj/6erz//lq8tmNmo5kC4SJOaG/iDFe/jq3d/kJmTmvjsUy/wMw99m7//wX4Hg5mNSg6ES7TwXdP4+q98mD9ccTP73jnNyj/fws889G02vbaX/n4Hg5mNHhqtf80uWrQoOjo6at2NEmd6+1m3tYv/861O3jpyivkzxvMLS97FikVtTGpuqHX3zMyQtDUiFlXaNuQZgqS5kr4l6VVJ2yR9JtWnSdogaUdaTi1qc5+kTknbJd1eVF8o6aW07UFJSvUmSU+l+mZJ8y551DXQWJ/j3//4NTz7Gx/lT9pvYdr4Rv7HN15hye9v5LfWvch3fnjQZw1mNmINeYYgaTYwOyK+J2kisBW4A/iPwKGI+Jyke4GpEfFbkm4AvgIsBq4G/h9wXUT0SdoCfAb4DvB/gQcj4hlJvwLcHBG/LKkd+JmI+HeD9WskniFU8vJbR3n8uTf5mxf3cOJMH1dPbmb5rXP4xE2zuWnOJFImmpldEYOdIVzwlJGkp4E/S6+PRsSeFBrPRsR7Jd0HEBH/K+3/d8DvAm8C34qI61P951L7Txf2iYjnJNUDbwOtMUjnRksgFJw808uGV/by9eff4h92HKCvP7hqUjMfu2EmH7/hKpa8expN9XW17qaZjXGDBUL9BR5oHnArsBmYFRF7AFIozEy7zSF/BlDQlWo9ab28XmizKx2rV9JRYDpwoOznrwZWA1xzzTUX0vWaG9dYz/Jb5rD8ljkcOnGGTa/tY8Mrb/PVrW/xpe/spKk+x6J5U/nQe2bwofdM51/MmUx9na/5m9mVU3UgSJoAfBX4bES8M8hUR6UNMUh9sDalhYhHgEcgf4YwVJ9HqmnjG1mxsI0VC9s43dPHt18/wD/tOMi3Xz/AH/7ddgAmNNVz6zVTuGXu2df0CU017rmZjWVVBYKkBvJh8OWI+OtU3itpdtGU0b5U7wLmFjVvA3aneluFenGbrjRlNBk4dBHjGXWaG+q47fpZ3Hb9LAAOHu/mOz88xLdfP8DzO4/w0LOv05cuRM+d1sLNbVP4sasm8t6rJnH9VROZM6WFXM7XIczs0g0ZCOlOoEeBVyPi80Wb1gMrgc+l5dNF9b+U9HnyF5UXAFvSReVjkpaQn3K6C/jTsmM9B6wANg12/WAsmz6hiU/ePJtP3jwbyF97ePmtd3hh12Fe2HWEF7uO8Dcv7hnYf3xjHdddNZH3zprI/BnjmTdjPPOmj+dd08fR3OBrEmZWvWrOED4M/ALwkqQXUu2/kg+CtZJWATuBOwEiYpuktcArQC9wT0QUHg16N/AY0AI8k16QD5wnJHWSPzNov7RhjR3jGutZPH8ai+dPG6gd7+7lB3uP8dqeY2x/+x1ee/sYG17Zy8ETZwb2kWD2pGbmzRjPNdPGcfWUFmZPbmbOlBZmp3UHhpkV8wfTxpCjp3r40cETvHnwJG8eOMGbB07wxsETdB0+xf5j3efsP318I7OnNHPVpGZmTGhKr0ZmTGwaeN86oYlJLfW+PdZsjLhsdxnZyDa5pYGb26Zwc9uUc7Z19/ax92g3bx05xe4jp9hz9BRvHTnN7iP55fe7jnLweDeVPjfXWJdj6vgGprQ0MrmlgcnjGpjc0sCUlrQc18DkcY0DtYnN9Uxoqmd8Uz3jGuscJmajhAMhI5rq67hm+jiumT7uvPv09weHT57hwPEzHDjezYHj3ew/1s3+490cOn6Go6d6OHqqh12HTvLyqR6OnOzh1BBfFCTB+MZ8MBRCYnxTXVFg1DOhqY6WxnqaG3I019fR3FCXXy8s6+toKqnV0Vx/dr3OF9XNLgsHgg3I5cT0CU1Mn9DEe5lYVZvu3j6OnurhnRQQR072cKy7h+PdfZzo7k2v/PrxM70Dtd1HTnMivT/e3cvpnv6L7nd9TjTU5WioE431ubSeo75ONNblBrY11OWKtov6ulzaroE2DXUilxN1EvW5/HrJMtXrymt1hW056nKcU8vlKNmWk5CouMwJJCFK9z27vcL7tK9yDNqucGyzShwIdkma6uuYObGOmRObL+k4/f3Bmb5+Tvf0cbonLXuL1lO9u7eP7p7+tO1srbcv376nr5+e3qCnr//s+770vrefE929A++LtxW29/QFfRH09we9Y/i5UwMhVPQeYKAizrtNJdtU2L1CO5W1P3d/FTUs3q/855677WyoDWwbpJ9DqSYkqzpWFTtVc5yh+vOZpQv4N++7upoeXRAHgo0IuZxoztWNuDuf+vvzAdHXn3/19p8Ni/6iel9RrbcvLVO9vNbfHwRBfz/0RxBARNAfEJGv9UcQQel+hfdR9D5K31ezX3/+B9KXbigp3FdSiL9C++Li2W1Rcf/8+7PbKNq/sG/xfuU/92y7sm1Ref+q+nm+/6hlqrmvpppjVXODTlV9qmKnyS3D8/RkB4LZIHI5kUOMsJwyGxZ+WI6ZmQEOBDMzSxwIZmYGOBDMzCxxIJiZGeBAMDOzxIFgZmaAA8HMzJJR+/hrSfuBH11k8xmUfV9zBnjM2eAxZ8OljPldEdFaacOoDYRLIanjfM8DH6s85mzwmLNhuMbsKSMzMwMcCGZmlmQ1EB6pdQdqwGPOBo85G4ZlzJm8hmBmZufK6hmCmZmVcSCYmRmQwUCQtEzSdkmdku6tdX8uF0l/LmmfpJeLatMkbZC0Iy2nFm27L/0Otku6vTa9vniS5kr6lqRXJW2T9JlUH8tjbpa0RdL305h/L9XH7JgLJNVJel7SN9L7LIz5TUkvSXpBUkeqDe+481+Jl40XUAe8DrwbaAS+D9xQ635dprF9BHg/8HJR7Q+Ae9P6vcADaf2GNPYmYH76ndTVegwXON7ZwPvT+kTgB2lcY3nMAiak9QZgM7BkLI+5aOz/BfhL4BvpfRbG/CYwo6w2rOPO2hnCYqAzIn4YEWeAJ4HlNe7TZRER/wAcKisvB9ak9TXAHUX1JyOiOyLeADrJ/25GjYjYExHfS+vHgFeBOYztMUdEHE9vG9IrGMNjBpDUBnwS+GJReUyPeRDDOu6sBcIcYFfR+65UG6tmRcQeyP8DCsxM9TH1e5A0D7iV/F/MY3rMaerkBWAfsCEixvyYgT8GfhPoL6qN9TFDPuy/KWmrpNWpNqzjrr+Ezo5GqlDL4n23Y+b3IGkC8FXgsxHxjlRpaPldK9RG3Zgjog+4RdIU4GuSbhpk91E/Zkk/DeyLiK2SPlpNkwq1UTXmIh+OiN2SZgIbJL02yL6XZdxZO0PoAuYWvW8DdteoL1fCXkmzAdJyX6qPid+DpAbyYfDliPjrVB7TYy6IiCPAs8AyxvaYPwx8StKb5Kd4b5P0Jcb2mAGIiN1puQ/4GvkpoGEdd9YC4bvAAknzJTUC7cD6GvdpOK0HVqb1lcDTRfV2SU2S5gMLgC016N9FU/5U4FHg1Yj4fNGmsTzm1nRmgKQW4GPAa4zhMUfEfRHRFhHzyP//uikifp4xPGYASeMlTSysAz8JvMxwj7vWV9JrcOX+E+TvSHkd+O1a9+cyjusrwB6gh/xfC6uA6cBGYEdaTiva/7fT72A78FO17v9FjPcnyJ8Svwi8kF6fGONjvhl4Po35ZeC/p/qYHXPZ+D/K2buMxvSYyd8J+f302lb4t2q4x+1HV5iZGZC9KSMzMzsPB4KZmQEOBDMzSxwIZmYGOBDMzCxxIJiZGeBAMDOz5P8DqdXZH27G1u8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jsnar\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LEARNING_RATE = 0.5\n",
    "LAMBDA = 100\n",
    "MAX_ITER = 500\n",
    "\n",
    "\n",
    "# first we do the pre-processing to make it easier for our gradient descent\n",
    "pca_data_train, pca_data_test = apply_pca(data_train, data_test, n_components=95)\n",
    "\n",
    "# getting the unique labels that we have in dataset\n",
    "labels = np.arange(np.max(label_train))\n",
    "\n",
    "optimal_weights = np.zeros((pca_data_train.shape[1], len(labels)))\n",
    "\n",
    "for label in labels:\n",
    "    X0 = pca_data_train[np.where(label_train!=label)[0], :]\n",
    "    X1 = pca_data_train[np.where(label_train==label)[0], :]\n",
    "    y0 = np.zeros(X0.shape[0])\n",
    "    y1 = np.ones(X1.shape[0])\n",
    "\n",
    "    X = np.concatenate((X0, X1), axis=0)\n",
    "    y = np.concatenate((y0, y1))[:, np.newaxis]\n",
    "    \n",
    "    N, D = X.shape\n",
    "    \n",
    "    # select a random starting point for our gradient descent\n",
    "    weights = np.random.random(D)[:, np.newaxis]\n",
    "    \n",
    "    loss_array = []\n",
    "\n",
    "    for _ in range(MAX_ITER):\n",
    "        dloss, current_loss = calc_logistic_loss(weights, X, y, LAMBDA)\n",
    "        weights = weights - (LEARNING_RATE * (dloss / N))\n",
    "\n",
    "        loss_array.append(current_loss)\n",
    "\n",
    "    plt.plot(list(range(MAX_ITER)), loss_array)\n",
    "    plt.show()\n",
    "    \n",
    "    optimal_weights[:, label] = np.squeeze(weights)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7655\n"
     ]
    }
   ],
   "source": [
    "probability_matrix = pca_data_test.dot(optimal_weights)\n",
    "predictions = np.argmax(probability_matrix, axis=1)\n",
    "accuracy = calc_top1_accuracy(predictions, label_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logistic_loss(weights, X, y):\n",
    "    \n",
    "    # produce vector z, which is what we'll feed into the sigmoid function\n",
    "    z = np.dot(X, weights)\n",
    "    exp_z = np.exp(z)\n",
    "    \n",
    "    # obtaining a vector on difference between our probability against actual value of y\n",
    "    # which we then apply a broadcast multiplication against matrix X, to create N by D matrix\n",
    "    # and then we sum it to obtain the sum of loss for each feature\n",
    "    dloss = np.sum((exp_z/(1+exp_z) - y) * X, axis=0)\n",
    "    \n",
    "    # calculating the loss\n",
    "    loss = -np.sum(-np.log(1+exp_z) + (y*z))\n",
    "    \n",
    "    return dloss, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(data_train.shape) != 2:\n",
    "        data_train = data_train.reshape((data_train.shape[0], data_train.shape[1]**2))\n",
    "\n",
    "X0 = data_train[np.where(label_train==0)[0], :]\n",
    "X1 = data_train[np.where(label_train==1)[0], :]\n",
    "y0 = np.zeros(X0.shape[0])\n",
    "y1 = np.ones(X1.shape[0])\n",
    "\n",
    "X = np.concatenate((X0, X1), axis=0)\n",
    "y = np.concatenate((y0, y1))[:, np.newaxis]\n",
    "\n",
    "N, D = X.shape\n",
    "\n",
    "# select a random starting point for our stochastic gradient descent\n",
    "weights = np.random.random(D)[:, np.newaxis]\n",
    "print(weights.shape)\n",
    "\n",
    "learning_rate = 0.1\n",
    "max_iter = 1000\n",
    "\n",
    "loss_array = []\n",
    "\n",
    "for epoch in range(max_iter):\n",
    "    dloss, current_loss = calc_logistic_loss(weights, X, y)\n",
    "    weights = weights - (learning_rate * dloss/N)\n",
    "    \n",
    "    loss_array.append(current_loss)\n",
    "\n",
    "print(loss_array)\n",
    "    \n",
    "plt.plot(list(range(1,max_iter+1)), loss_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
